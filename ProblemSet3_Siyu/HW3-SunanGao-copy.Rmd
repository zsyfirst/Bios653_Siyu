---
title: "Problem Set 3 Longitudinal Bootstrap Code"
output: pdf_document
---




```{r load packages, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(warning = FALSE)
library(nlme)
library(tidyverse)
library(gee)
library(lmtest)
library(splines)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(boot)

options(digits = 3)
```

## Question-1
### Load the data and create the parity variable
```{r}
## Q1.1
load("nepal.anthro.rdata")
d0 = nepal.anthro[,c("id", "alive", "age", "wt","fuvisit","sex")]
d0$female = factor(ifelse(d0$sex==2,1,0),levels=0:1,labels=c("Male","Female"))
#install.packages("anthro")
library(anthro)
zscores = with(d0,
               anthro_zscores(
                 sex = sex,
                 age = age,
                 weight = wt,
                 is_age_in_month = TRUE
               ))$zwei
d = cbind(d0,zscores)[complete.cases(d0) & d0$age<=60,]
```

### Part-2.2
Identify the number of children in the sample, overall and for each sex.  Calculate the number of visits for each child with non-missing weight-for-age z-scores and compute the average and quartiles of the number of visits for each child by sex.

```{r}
data = d %>% filter(!is.na(zscores))
table(data$female)
cat('\nThe number of children (overall):',dim(d)[1])
cat('\nThe number of children (Female):',sum(data$female == 'Female'))
cat('\nThe number of children (Female):',sum(data$female == 'Male'))

# colnames(data)
visits_per_child <- aggregate(fuvisit ~ id + sex, data=data, FUN=length)
average_visits_by_sex <- aggregate(fuvisit ~ sex, data=visits_per_child, FUN=mean)
quartiles_visits_by_sex <- aggregate(fuvisit ~ sex, data=visits_per_child, 
                                     FUN=function(x) quantile(x, probs=c(0.25, 0.5, 0.75)))
```


### Part-1.3
Make a spaghetti plot of children’s weight-for-age z-scores as a function of age; connecting the measured weights within a child over time. Color code the data by sex.  Add smoothing splines for each sex.  Note any similarities or differences in the growth rates across the groups.

```{r, warning=FALSE}
library(ggplot2)

custom_theme <- theme(
  panel.background = element_blank(),
  axis.ticks = element_blank(),
  axis.text = element_text(size = 12),
  axis.title = element_text(size = 12, face = "bold"),
  axis.line = element_line(size = 0.5),
  plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
)

plot13 = ggplot(d, aes(x = age, y = zscores, group = id, color = female)) +
  geom_line() + # Spaghetti plot, connecting measurements within each child
  geom_smooth(method = "loess", se = FALSE) + 
  theme_minimal() + 
  labs(title = "Children's Weight-for-Age Z-Scores Over Time",
       x = "Age (Months)",
       y = "Weight-for-Age Z-Scores") + 
  custom_theme + 
  theme(legend.key = element_blank(),
        legend.title = element_blank()) + 
  scale_color_manual(values = c("Male" = "blue", "Female" = "pink")) # Color code by sex

plot13
```
Similarities:
- Both male and female children display a wide range of growth trajectories, as evidenced by the spread of lines across the z-score range.
There is a general trend where both groups show an increase in z-scores as age increases, which is expected as children grow over time.

Differences:
The plot suggests that there is some variation between the two sexes. For example, there appears to be a cluster of female trajectories (cyan lines) that are consistently higher compared to the males (red lines), particularly in the middle age range. This could suggest a period where female children are experiencing faster growth relative to the male children in this sample.
Some male trajectories (red lines) exhibit sharper declines or more pronounced fluctuations in z-scores than the female trajectories. This could indicate a greater variability in growth rates or measurement timing among male children.


## Question-2
### Part-2.1
#### Build the model
```{r}
library(lmtest)
colnames(data)
model21 = lm(zscores ~ age + female + female*age, 
             data = data)
summary(model21)

data$model21_res = residuals(model21)
```

#### Check the normal distribution
```{r}
plot(model21)
```

#### Check the mean model
```{r}
ggplot(data,
       aes(x = age, y = model21_res, color = female)) +
  geom_point() + 
  geom_smooth(method = "loess") + 
  custom_theme + 
  labs(x = "Age (in months)", y = "Estimated variance")
```

#### Check the independence of the model
```{r}
data_wide_res <- data |>
  select(id, fuvisit, model21_res) |>
  pivot_wider(id_cols = "id",
              names_from = "fuvisit",
              values_from = "model21_res")
data_wide_res_comp = data_wide_res[complete.cases(data_wide_res),]

cor(data_wide_res_comp[,c(2:6)])
pairs(data_wide_res_comp[,c(2:6)])
```

#### Check the Constant Variance Assumption
```{r}
ggplot(data,
       aes(x = age, y = model21_res^2, color = female)) +
  geom_point() + 
  geom_smooth(method = "loess") + 
  custom_theme + 
  ylim(0,10) + 
  labs(x = "Age (in months)", y = "Estimated variance")
```


### Part-2.2
Based on your model checking, propose an alternative model for the data that can address the first goal of the analysis, i.e. determine if the growth rates of children differ by sex while satisfying the observed patterns in data with respect to the mean model and distribution of residuals.

```{r}
## Fit the alternative model
data = data |> 
  mutate(age_s12 = ifelse(age>12, age-12, 0))

model22 <- lm(zscores ~ age + age_s12 + female + 
                age:female + 
                age_s12:female, data = data)
summary(model22)
data$model22_res = residuals(model22)
```
#### Check the normal distribution
```{r}
plot(model22)
```

#### Check the mean model
```{r}
ggplot(data,
       aes(x = age, y = model22_res, color = female)) +
  geom_point() + 
  geom_smooth(method = "loess") + 
  custom_theme + 
  labs(x = "Age (in months)", y = "Estimated variance")
```

#### Check the independence of the model
```{r}
data_wide_res <- data |>
  select(id, fuvisit, model22_res) |>
  pivot_wider(id_cols = "id",
              names_from = "fuvisit",
              values_from = "model22_res")
data_wide_res_comp = data_wide_res[complete.cases(data_wide_res),]

cor(data_wide_res_comp[,c(2:6)])
pairs(data_wide_res_comp[,c(2:6)])
```

#### Check the Constant Variance Assumption
```{r}
ggplot(data,
       aes(x = age, y = model22_res^2, color = female)) +
  geom_point() + 
  geom_smooth(method = "loess") + 
  custom_theme + 
  ylim(0,10) + 
  labs(x = "Age (in months)", y = "Estimated variance")
```



## Question-3
### Part-3.1
Use the gls function in R to fit the model you proposed in Part I.
```{r}
model31 = gls(zscores ~ age + age_s12 + female + 
                age:female + 
                age_s12:female,
              data = data,
              correlation = corAR1(form = ~fuvisit|id),
              weights = varFunc(~as.numeric(female)))
summary(model31)
```

### Part-3.2
From the fit of the model, compute the estimated Corr($\epsilon_{i1}$, $\epsilon_{ij}$) for j = 2,3,4,5 where the follow-up visits (fuvisit) have values 0 (baseline, j=1) and 1,2,3,4 (representing the 4 follow-up visits each 4 months apart,j = 2,3,4,5).
Compare these model-based correlation estimates to those you computed in Part II Question1.
```{r}
library(nlme)
summary(model31)$tTable

female.V = getVarCov(model31, individual=3)
cov2cor(female.V) # obtain correlation matrix
male.V = getVarCov(model31,individual=7)
cov2cor(male.V)
```
Select the male and female individual seperately, and the extract the variance matrix from there. We obatin the same correlation matrix. It aligns our expectations, because we assume that correlation martix for each individual in different visits.


### Part-3.3
Conduct a Wald test to address the overall goal of the analysis; i.e. to determine if the average growth rates of children differ by sex. 
Under the null hypothesis, Q follows a chi-square distribution with s degrees of freedom.  Report the test statistic Q and your decision to reject or fail to reject the null hypothesis that the average growth rates are the same by sex.
```{r}
var_beta_hat = model31$varBeta
beta_hat = model31$coefficients
C <- matrix(c(0,0,0,1,0,0,
              0,0,0,0,1,0,
              0,0,0,0,0,1), 
            ncol = 6, nrow = 3, byrow = TRUE)
  # The contrast matrix for the hypothesis you are testing.
s = nrow(C)

Q <- t(C %*% beta_hat) %*% solve(C %*% var_beta_hat %*% t(C)) %*% (C %*% beta_hat)
cat('The test statistic Q is:',Q)
1-pchisq(Q, s) 
  # p=0.192>0.05, we don't reject the null hypothesis.
```
under the null hypothesis, Q-statistics is 0.192 here, larger than 0.05. It suggests that the average growth rates of children doesn't differ by sex.

## Question-4
### Part-4.1a
Show that the robust variance estimator is equal to the generalized least squares variance estimator when $\Sigma_w$ is correctly specified.

### Part-4.1b
For the model you fit in Part III Question1, obtain the robust standard error estimates using the Huber-White sandwich estimator. Compare the estimated model based and robust standard errors.

```{r}
#install.packages("clubSandwich")
library(clubSandwich)
# Fit the model
model41 <- gls(zscores ~age + age_s12 + female + age*female + age_s12*female, data = data, correlation = corAR1(form= ~fuvisit|id), weights = varFunc(~as.numeric(female)))

# Estimate robust standard errors using the cluster-robust sandwich estimator
# This is the robust estimate of Var-hat(beta-hat)
vcov.rob <- vcovCR(model41, cluster = data$id, type = "CR0")
# Save the results for testing each individual coefficient
clubsand_41 <- coef_test(model41, vcov = vcov.rob)
# Compare the standard errors
summary(model41)$tTable
clubsand_41

```

### Part-4.1c
Using the results of a. and b. above, do the data support or not support your working model for the variance/covariance of the residuals?

For the results in a and b. We can see the robust standard errors are lager than the standard error. It suggests the model we assumed before is not correct enough (i.e. ).


### Part-4.1d
Use the robust variance estimate for $\hat\beta$ you obtained (called vcov.rob in the code above) and repeat the Wald test you conducted in Part III Question 3.  Are the results of the Wald tests the same or different?
```{r}
var_beta_hat = vcov.rob
beta_hat = model41$coefficients
C <- matrix(c(0,0,0,1,0,0,
              0,0,0,0,1,0,
              0,0,0,0,0,1), 
            ncol = 6, nrow = 3, byrow = TRUE)
s = nrow(C)

Q <- t(C %*% beta_hat) %*% solve(C %*% var_beta_hat %*% t(C)) %*% (C %*% beta_hat)
cat('The test statistic Q is:',Q)
1-pchisq(Q, s) # p>0.05, we don't reject the null hypothesis.
```
The results are little different. But we also fail to reject the null hypothesis because p-value over 0.5.

### Part-4.2a
Instead of modelling the variance/covariance of the within subject residuals, you could assume an independence working model with constant variance, i.e. fit the model using ordinary least squares, and apply a robust variance estimate for $\hat\beta$ for inference on $\beta$.


Use the lm command to refit your model under working independence and constant variance; then obtain a robust variance estimate for $\hat\beta$
```{r}
# Fit the ordinary least squares model
fit.ols = lm(zscores ~ age + age_s12 + female + 
                age:female + 
                age_s12:female,
             data = data)

# Get the robust variance estimate
vcov.rob.ols <- vcovCR(fit.ols, cluster = data$id, type = "CR0")
# Save the results for testing each individual coefficient
clubsand.ols <- coef_test(fit.ols, vcov = vcov.rob.ols)
# Compare the standard errors for the estimated coefficients
summary(fit.ols)$coeff
clubsand.ols
```
The robust variance estimate is almost same to the standard error estimates from OLS model. It suggests the model we assume is relatively correct.

### Part-4.2b
Recalculate the Wald test using the robust variance estimate for $\hat\beta$ from the working independence and constant variance model.
```{r}
var_beta_hat = vcov.rob.ols
beta_hat = fit.ols$coefficients
C <- matrix(c(0,0,0,1,0,0,
              0,0,0,0,1,0,
              0,0,0,0,0,1), 
            ncol = 6, nrow = 3, byrow = TRUE)
s = nrow(C)

Q <- t(C %*% beta_hat) %*% solve(C %*% var_beta_hat %*% t(C)) %*% (C %*% beta_hat)
cat('The test statistic Q is:',Q)
1-pchisq(Q, s) # p>0.05, we fail to reject the null hypothesis.
```

### Part-4.2c
Compare the estimated standard errors for $\hat\beta$ and the Wald test results based on your three approaches:  
i) assuming your working model is correct (Part III); ii) a robust variance estimate applied to your working model (Part IV Question 1); iii) a robust variance estimate applied to a working independence/constant variance model (Part IV Question 2).
```{r}
## i) assuming your working model is correct (Part III); 
summary(model31)

## ii) a robust variance estimate applied to your working model (Part IV Question 1)
clubsand_41

##iii) a robust variance estimate applied to a working independence/constant variance model (Part IV Question 2).
clubsand.ols
```
We can see the standard error and robust variance estimate in OLS methods are nearly same, supporting the model assumption is correct. And the robust variance estimate for OLS and GLM (with correlation and variation assumption) are similar, both higher than the standard error in GLM model. It suggests the assumption of GLM may not be correct.

### Part-4.3a
The bootstrap procedure can also be applied to longitudinal or clustered data to estimate standard errors of estimated coefficients. To preserve the within-subject dependency, the bootstrap procedure samples children (with replacement) as opposed to assessments. See the ProblemSet3.rmd file for code to implement a clustered bootstrap. 

#### Longitudinal or clustered data bootstrap procedure
Create a function that will take a bootstrap sample of children (with replacement) and fit the mean model of interest. The bootstrap procedure will require some transformations of the data from long to wide to long again.

```{r clusteredbootstrap}
# Create a wide version of the data
# Each row represents an individual child

nepal.wide <- d[,c('id','age','zscores','female','fuvisit')] %>%
  #mutate(age_s12=ifelse(age>=12, age-12, 0)) %>%
  pivot_wider(id_cols=c(id,female),
              values_from = c(age,zscores),
              names_from='fuvisit')

## Write a bootstrap function 
my.boot <- function(data, id){
  # Resample the children
  dt <- data[id, ]
  # Create a new id variable and drop the old id
  dt$id = NULL
  dt$id = seq(1,nrow(dt))
  # Convert to the long format for model fitting
  dlong0 = pivot_longer(dt,cols=!c(id,female),
                    names_to=c("vars","fuvisit"),
                    names_sep="_",values_to = "y")
  dlong = pivot_wider(dlong0,names_from="vars",values_from="y")
  # Fit the mean model
  # NOTE:  We can use a ordinary least squares procedure here
  # since this procedure produces unbiased estimates of the model
  # coefficients even when the correlation or variance assumption
  # is violated
  fit = lm(zscores ~ age + I(I(age>=12)*(age-12)) + female + 
                age:female + 
                I(I(age>=12)*(age-12)):female, dlong)
  coefficients(fit)
}

result = boot(nepal.wide, my.boot, 1000)
boot.V <- cov(result$t)
boot.se <- sqrt(diag(boot.V))
boot.se
```
Comment on similarities and differences.


### Part-4.3b
Repeat the Wald test using the bootstrap estimate of the variance of β ̂.  NOTE: you can use Comment on similarities and differences.
```{r}
var_beta_hat = boot.V
beta_hat = result$t0
C <- matrix(c(0,0,0,1,0,0,
              0,0,0,0,1,0,
              0,0,0,0,0,1), 
            ncol = 6, nrow = 3, byrow = TRUE)
s = nrow(C)

Q <- t(C %*% beta_hat) %*% solve(C %*% var_beta_hat %*% t(C)) %*% (C %*% beta_hat)
cat('The test statistic Q is:',Q)
1-pchisq(Q, s) # p>0.05, we fail to reject the null hypothesis.
```
Comment on similarities and differences:



## Question-5
### Part-5.1(<1000 words)
Objective: 
Data:
Methods:
Results:




•	In your methods section, be sure to describe the model you fit in Part III and the sensitivity analyses you performed in Part IV.
•	In the results section, provide your findings from Part III and then discuss whether your results were similar in the sensitivity analyses.
•	You may include up to 2 tables/figures (which may have multiple panels).
•	Remember to be enumerate when possible!











